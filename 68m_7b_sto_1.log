[2024-02-01 01:49:50,603] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(model='JackFram/llama-68m', target='meta-llama/Llama-2-7b-hf', dataset='dataset/c4_small.json', start=0, end=200, T=1.0, P=1.0, DP=0.99, ALG='coverplus', D=1, B=10, W=32, M=288, Mode='greedy', decay=0.85, negative=False, static=False, offloading=False)
1.8823529411764706
1.8759124087591241
1.8780487804878048
1.8654545454545455
1.868804664723032
1.880195599022005
1.8905263157894736
1.8895131086142323
1.8895131086142323
1.888704318936877
1.886736214605067
1.89280868385346
1.89280868385346
1.8919254658385094
1.886467889908257
1.8892438764643238
1.8898305084745763
1.8865877712031558
1.8866080156402738
1.890625
1.8886925795053005
1.8886925795053005
1.8923205342237062
1.8933969769291965
1.8935849056603773
1.8964773544212796
1.896504455106237
1.9008535784635587
1.899497487437186
1.9005424954792043
1.9027373325567851
1.9018583042973287
1.9018583042973287
1.9021799888205702
1.9004305705059203
1.8987206823027718
1.8987206823027718
1.8971722365038561
1.8966716343765524
1.8952929875120077
1.8957654723127035
1.8966606498194947
1.8970652650021902
1.8982545764154959
1.8990066225165563
1.8990066225165563
1.8970233306516493
1.899607843137255
1.9017208413001911
1.9019388516032811
1.9021462349945435
1.9020234291799787
1.9019064124783363
1.9018531228551818
1.9020462931902047
1.9020462931902047
1.9013114754098361
1.9016927083333333
1.9000636537237428
1.9008728179551122
1.9004884004884004
1.8998500749625187
1.9008823529411765
1.8980708321336022
1.8983050847457628
1.8983050847457628
1.898281596452328
1.8998094200925675
1.9002673796791443
1.8994486741927015
1.8994067578024245
1.898150494046111
1.898355754857997
1.8987993138936534
1.8989874638379942
1.8996203132415757
1.9004672897196262
1.9006211180124224
1.9001835704451584
1.9003389830508475
1.89957312963379
1.8992901508429458
1.8990384615384615
1.8990384615384615
1.8998276604911677
1.8999787640688044
1.8999787640688044
1.9003350083752093
1.9003350083752093
1.9006813958290316
1.8992673992673992
1.9
1.9007134363852556
1.900355871886121
1.9008587041373926
1.9010477299185098
1.899540757749713
1.9003969003969003
1.9003209363790825
1.9009882528435578
1.901639344262295
1.9014524728810442
1.9015619324373412
1.9006456241032998
1.900088573959256
1.9002100840336134
1.9
1.8996409642673961
1.8996409642673961
1.8995043582293625
1.8994762628822437
1.9002339572192513
1.9001982815598149
1.9007845701209545
1.901050929668553
1.9003996802557954
1.9004274180782017
1.9004274180782017
1.9011281729865246
1.9012365002347784
1.9013320941759604
1.9013888888888888
1.9010535959688502
1.9017236165709102
1.9009575104727707
1.9010516960450303
1.901422913304973
1.901214693399678
1.9015799391216117
1.9015799391216117
1.9020818377602298
1.9024320864741857
1.90304396843292
1.9029871580122837
1.9035827915340988
1.9035378662244333
1.9037381897850199
1.9036865732553394
1.9040043144128354
1.9039207814799946
1.9043005043801433
1.9036860879904876
1.9037454164484022
1.903933532389978
1.9030177972659272
1.9025949124376837
1.902547205677354
1.9023746701846966
1.9023746701846966
1.9026791277258568
1.9029786182177728
1.9029786182177728
1.902929280549087
1.9026494895478854
1.9024831243973
1.9030020332496114
1.9031798766018035
1.9031190926275992
1.9031190926275992
1.9028564683663833
1.902867933435619
1.9020365168539326
1.9023228803716608
1.9024051803885291
1.9026853339453753
1.9030751708428246
1.9028138772742682
1.902945491479517
1.902575587905935
1.9028457092040907
1.9034322922414744
1.9033432638199272
1.9034778780541493
1.9040542017265873
1.9040288241074352
1.9041838283112942
1.9041838283112942
1.9045415411106328
1.904398322400258
1.9041711229946523
1.9044180118946474
1.9047669268086902
1.904607329842932
1.904449989602828
1.904449989602828
1.9042948585587445
1.9043371270378344
1.904470300061237
1.9045108971109985
1.9048434195952069
1.9051715514654397
1.9051715514654397
1.905306041335453
1.905250690880379
1.905250690880379
1.9049112832075288
1.9055041402825135
1.905536198219125
1.9058472783227545
1.9059722885809842
total decoding steps: 19946 large model steps: 10465 avg decoding step: 1.9059722885809842
tensor([0.5495, 0.0980, 0.0554, 0.0354, 0.0243, 0.0191, 0.0143, 0.0103, 0.0119,
        0.0101, 0.0062, 0.0064, 0.0056, 0.0063, 0.0053, 0.0050, 0.0046, 0.0042,
        0.0037, 0.0031, 0.0034, 0.0031, 0.0030, 0.0023, 0.0020, 0.0020, 0.0023,
        0.0020, 0.0016, 0.0015, 0.0018, 0.0021, 0.0940], device='cuda:0')
tensor([0.5495, 0.6476, 0.7030, 0.7384, 0.7626, 0.7817, 0.7961, 0.8064, 0.8183,
        0.8285, 0.8347, 0.8411, 0.8467, 0.8530, 0.8583, 0.8633, 0.8678, 0.8720,
        0.8758, 0.8788, 0.8823, 0.8853, 0.8883, 0.8906, 0.8926, 0.8946, 0.8969,
        0.8989, 0.9005, 0.9021, 0.9039, 0.9060, 1.0000], device='cuda:0')
