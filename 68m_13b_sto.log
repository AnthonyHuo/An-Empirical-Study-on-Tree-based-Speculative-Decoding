[2024-01-31 22:00:07,318] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(model='JackFram/llama-68m', target='meta-llama/Llama-2-13b-hf', dataset='dataset/c4_small.json', start=0, end=200, T=0.6, P=1.0, DP=0.99, ALG='coverplus', D=1, B=10, W=32, M=288, Mode='greedy', decay=0.85, negative=False, static=False, offloading=False)
1.8823529411764706
1.9037037037037037
1.9047619047619047
1.9114583333333333
1.915057915057915
1.9141104294478528
1.916030534351145
1.911062906724512
1.911062906724512
1.9092627599243857
1.9100346020761245
1.9130434782608696
1.9130434782608696
1.9047619047619047
1.899234693877551
1.899138991389914
1.9064994298745723
1.9088016967126193
1.9117938553022795
1.9170549860205033
1.9183494293239685
1.9183494293239685
1.9226932668329177
1.9220472440944882
1.9222139117427075
1.9237348538845331
1.924438393464942
1.9263363754889178
1.9275
1.9266666666666667
1.9282798833819241
1.9260089686098654
1.9260089686098654
1.9254457050243112
1.9239187076602398
1.9234375
1.9234375
1.9225352112676057
1.9221351616062683
1.9218067022826615
1.9219190968955786
1.9224452554744527
1.9229406554472985
1.9223300970873787
1.9228130360205833
1.9228130360205833
1.9212827988338192
1.9229521492295214
1.9239952248308794
1.9236434108527132
1.9236871930487345
1.9240692959823074
1.9251259899208064
1.9245014245014245
1.9251913709116215
1.9251913709116215
1.924201223657376
1.9258150365934796
1.9255952380952381
1.9240837696335078
1.9237912263848864
1.9253216190775024
1.920883164673413
1.9221286831028261
1.9216263995285798
1.9216263995285798
1.9225209598149755
1.923382519863791
1.923141186299081
1.9229287090558767
1.922453390975412
1.9217299018307243
1.9212926765702372
1.922583952832607
1.9218946837994457
1.9224287484510534
1.9223587223587224
1.922165820642978
1.9210651450309082
1.9217981737298058
1.9218786328760753
1.9225109220510461
1.922554347826087
1.922554347826087
1.9227303446722235
1.9219165927240462
1.9219165927240462
1.9211273760104872
1.9211273760104872
1.9209732988802757
1.920415959252971
1.920152091254753
1.9208168368410086
1.9212371134020618
1.920699471329809
1.9208021065424348
1.9200968523002422
1.9209320852419838
1.9206474536123175
1.9212629117131164
1.92149316913604
1.921907657229717
1.9217919514047077
1.9227306826706676
1.9206290471785383
1.921038201425699
1.9195236376759293
1.9192513368983957
1.9192513368983957
1.9193235864012683
1.91955423994428
1.9198129546241773
1.9197658402203857
1.919787014771556
1.9195246179966043
1.9195903978512674
1.91869918699187
1.91869918699187
1.9185393258426966
1.9186697398748764
1.9188925081433226
1.9190329385039753
1.9184852374839538
1.9193138500635325
1.9192204934779191
1.9191290824261276
1.9194889162561577
1.9188118811881187
1.9188781664656211
1.9188781664656211
1.918492945061543
1.918561450438401
1.918481459682166
1.918863503222027
1.918764637002342
1.9192402493837901
1.9186046511627908
1.9187223727363467
1.9193274936422717
1.9193841847445767
1.9194021511384272
1.9196042914866935
1.9195196024295968
1.9196990424076608
1.920135593220339
1.920440800967612
1.9204848161960575
1.9205948745186563
1.9205948745186563
1.9208898249308937
1.92004695448024
1.92004695448024
1.9199637962244633
1.9196129032258065
1.9196622745298708
1.9198274768489154
1.9203573225968797
1.9204516938519447
1.9204516938519447
1.920253794476238
1.9206466740713317
1.9208323073134697
1.9209819247679532
1.9215947649054774
1.921625195335978
1.9221135496183206
1.9222485207100592
1.9223813997181776
1.9220643056849953
1.9223121387283237
1.9224414869206057
1.922463850620517
1.9224858757062147
1.9228266965787997
1.9227323628219486
1.9228546020453534
1.9228546020453534
1.9233995584988963
1.92393686979395
1.9238385376999239
1.9241573033707866
1.9245546254561066
1.9245604688332445
1.924973544973545
1.924973544973545
1.9253809774040989
1.9257828810020876
1.9257800352441174
1.9256742845377806
1.9260660599243276
1.9258657459124606
1.9258657459124606
1.9262510088781275
1.9260227158508392
1.9260227158508392
1.9258181088134914
1.9261992619926198
1.9263846230060437
1.926469140663451
1.9264619597105417
total decoding steps: 19700 large model steps: 10226 avg decoding step: 1.9264619597105417
tensor([0.6161, 0.1000, 0.0509, 0.0287, 0.0191, 0.0172, 0.0128, 0.0099, 0.0079,
        0.0068, 0.0048, 0.0057, 0.0049, 0.0039, 0.0028, 0.0025, 0.0038, 0.0031,
        0.0029, 0.0025, 0.0032, 0.0022, 0.0014, 0.0018, 0.0022, 0.0017, 0.0011,
        0.0018, 0.0014, 0.0009, 0.0019, 0.0007, 0.0735], device='cuda:0')
tensor([0.6161, 0.7161, 0.7671, 0.7957, 0.8148, 0.8320, 0.8448, 0.8547, 0.8626,
        0.8695, 0.8742, 0.8799, 0.8848, 0.8887, 0.8916, 0.8941, 0.8979, 0.9010,
        0.9040, 0.9065, 0.9097, 0.9119, 0.9133, 0.9150, 0.9172, 0.9188, 0.9199,
        0.9217, 0.9230, 0.9239, 0.9258, 0.9265, 1.0000], device='cuda:0')
