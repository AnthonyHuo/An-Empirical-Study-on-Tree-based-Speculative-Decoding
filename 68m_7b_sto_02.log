[2024-02-01 01:29:36,524] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(model='JackFram/llama-68m', target='meta-llama/Llama-2-7b-hf', dataset='dataset/c4_small.json', start=0, end=200, T=0.2, P=1.0, DP=0.99, ALG='coverplus', D=1, B=10, W=32, M=288, Mode='greedy', decay=0.85, negative=False, static=False, offloading=False)
1.95
1.9534883720930232
1.966887417218543
1.9625
1.9644444444444444
1.951219512195122
1.9581993569131833
1.9575596816976126
1.9575596816976126
1.9592760180995474
1.9528487229862475
1.9581151832460733
1.9581151832460733
1.9577464788732395
1.9602272727272727
1.9635416666666667
1.9628297362110312
1.965478841870824
1.9636929460580912
1.9650145772594751
1.9652650822669104
1.9652650822669104
1.9671848013816926
1.9672935404742438
1.9613003095975232
1.9616801768607222
1.960646521433591
1.9623402824478817
1.9638942617666022
1.9632731958762886
1.9641311069882499
1.9654967281380131
1.9654967281380131
1.9650829994275902
1.9652317880794703
1.9652509652509653
1.9652509652509653
1.9647964796479649
1.9644373673036093
1.965605749486653
1.9662195727769498
1.9672604718343765
1.96823914058851
1.9687216681776971
1.9674439067311922
1.9674439067311922
1.967079948696024
1.9679567207657096
1.9683954619124797
1.968034727703236
1.9688221709006928
1.969571750563486
1.968541820873427
1.9683707245310775
1.96875
1.96875
1.968259629101284
1.9685178634594978
1.9692148045658942
1.969553450608931
1.9688947716743879
1.969539857420609
1.9701587301587302
1.970752955818295
1.970722781335773
1.970722781335773
1.9706937799043063
1.971244131455399
1.9710610932475885
1.9701834862385321
1.969338959212377
1.96988118264714
1.9685381068619474
1.9690749133564383
1.969077568134172
1.9695876288659795
1.970081135902637
1.969334330590875
1.9695242814667988
1.9697634723238235
1.9699951992318772
1.9699834554478846
1.969746334652083
1.969746334652083
1.9701903233203393
1.9699570815450644
1.9699570815450644
1.9690698709390297
1.9690698709390297
1.969504168494954
1.9690766550522647
1.9692935366115525
1.9695044472681067
1.9699122440451315
1.9699031127602555
1.9700976403580146
1.970086328046577
1.9702734839476814
1.9706457925636007
1.9710088906068806
1.9711777056690207
1.9715255515745804
1.9716840536512668
1.972017673048601
1.9707325940738047
1.9710691823899371
1.9703677258122099
1.9703546850185283
1.9703546850185283
1.970516399162596
1.9699948266942577
1.970322360566263
1.9704790823211875
1.9705337598922377
1.9705196535642904
1.9708305866842453
1.9704923377893708
1.9704923377893708
1.9707970313004195
1.9707807759859493
1.9709228824273073
1.9712140175219024
1.9711940529657737
1.9714767673669682
1.9716064378985727
1.971286831028262
1.971266934643442
1.9710682492581602
1.9710506980161646
1.9710506980161646
1.9707858603564126
1.9709159311242945
1.9710435779816513
1.9711688680585144
1.9714285714285715
1.9716836378853397
1.9716615980094
1.9712368168744008
1.9710872811185014
1.971336293903916
1.971221086605702
1.971321361565264
1.9713033080908728
1.9712855637513171
1.9715256008359456
1.9717616580310882
1.9710573707229226
1.9712128966223132
1.9712128966223132
1.9711965486613374
1.9714285714285715
1.9714285714285715
1.9715355805243446
1.971640866873065
1.9713794374155509
1.9713624177431148
1.971584038694075
1.9716856628674264
1.9716856628674264
1.9717857142857143
1.9719990548204158
1.9718210637548432
1.9720312317911666
1.9722382880277618
1.972442301067861
1.9726433375128234
1.9723950673153072
1.9723719676549865
1.9724606979596389
1.9725481514279388
1.9725244532366195
1.9726102138804016
1.9728001733853489
1.9729875161429187
1.9731722958529285
1.9732512472136716
1.9732512472136716
1.9728077571669478
1.9729842931937174
1.9729589183567342
1.9727300898667492
1.9727067514877898
1.9728848114169215
1.972461273666093
1.972461273666093
1.9720434432823812
1.9720251773403936
1.971910669975186
1.972087977118059
1.9722630598843478
1.9724359598714327
1.9724359598714327
1.9723412543825478
1.9722627737226277
1.9722627737226277
1.9724344714188993
1.972604056522157
1.9727715677844655
1.972375166128726
1.9724301279014684
total decoding steps: 20819 large model steps: 10555 avg decoding step: 1.9724301279014684
tensor([0.7151, 0.0871, 0.0388, 0.0230, 0.0171, 0.0131, 0.0077, 0.0073, 0.0074,
        0.0060, 0.0068, 0.0046, 0.0039, 0.0033, 0.0030, 0.0027, 0.0019, 0.0032,
        0.0019, 0.0013, 0.0020, 0.0020, 0.0014, 0.0011, 0.0025, 0.0014, 0.0018,
        0.0014, 0.0010, 0.0013, 0.0011, 0.0011, 0.0263], device='cuda:0')
tensor([0.7151, 0.8022, 0.8410, 0.8640, 0.8812, 0.8943, 0.9019, 0.9092, 0.9166,
        0.9226, 0.9294, 0.9341, 0.9379, 0.9413, 0.9443, 0.9470, 0.9489, 0.9522,
        0.9541, 0.9554, 0.9574, 0.9594, 0.9608, 0.9619, 0.9644, 0.9658, 0.9676,
        0.9690, 0.9701, 0.9714, 0.9725, 0.9737, 1.0000], device='cuda:0')
