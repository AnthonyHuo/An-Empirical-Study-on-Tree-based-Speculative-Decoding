[2024-01-31 13:51:38,754] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(model='JackFram/llama-68m', target='meta-llama/Llama-2-7b-hf', dataset='dataset/c4_small.json', start=0, end=200, T=0.6, P=1.0, DP=0.99, ALG='cover', D=1, B=10, W=32, M=384, Mode='benchmark', decay=0.85, negative=False, static=False, offloading=False)
2.0
1.9844961240310077
1.9793814432989691
1.9753694581280787
1.9485294117647058
1.9467455621301775
1.9528535980148884
1.946808510638298
1.946808510638298
1.949532710280374
1.946843853820598
1.951951951951952
1.951951951951952
1.9495225102319236
1.94625
1.9502314814814814
1.9536637931034482
1.9546827794561934
1.954674220963173
1.9537777777777778
1.9554621848739495
1.9554621848739495
1.9577352472089313
1.959059893858984
1.9581227436823105
1.9586206896551723
1.95778364116095
1.959493670886076
1.9610705596107056
1.9616066154754872
1.9624573378839592
1.9637760702524698
1.9637760702524698
1.9644939056703763
1.9636456733230927
1.9631525076765608
1.9631525076765608
1.9633481921743436
1.9616490891658678
1.9618781961878196
1.961659900766802
1.9605954465849387
1.961260110685398
1.9618889809444904
1.9628732849071833
1.9628732849071833
1.9607227022780833
1.9616858237547892
1.9622429906542056
1.9609773887673232
1.9618674269422667
1.9623824451410659
1.9602040816326531
1.960067681895093
1.9586503473370824
1.9586503473370824
1.9569718537690068
1.9578446909667195
1.9583850931677018
1.959196102314251
1.9593908629441625
1.9601523586287724
1.9606095457159287
1.9610499576629974
1.9611973392461197
1.9611973392461197
1.9613395044922406
1.9614767255216694
1.9598108747044918
1.9592152813629324
1.9593805534399593
1.9578343313373254
1.9560951680156977
1.956773726153103
1.9565010696458285
1.9569288389513109
1.9575645756457565
1.957519309404816
1.9579135885381689
1.9574327304808117
1.9573913043478262
1.957136733819117
1.9575142675967026
1.9575142675967026
1.95767306088407
1.9580333264760337
1.9580333264760337
1.9585786802030456
1.9585786802030456
1.9589178356713426
1.9582756575044493
1.958609918000781
1.9587430113745903
1.959063214013709
1.9582706766917293
1.9587667161961366
1.9562030419644494
1.9563563926113727
1.9568564267812387
1.9571757211113077
1.957487753673898
1.9579584775086505
1.9582549187339606
1.9587070570316467
1.9571834754975748
1.957636935297038
1.9567992145311732
1.9566132426744374
1.9566132426744374
1.956431202947301
1.9564114756696782
1.9568492075945394
1.9572782352027343
1.9573180195561075
1.9574370006146282
1.957553628480146
1.957523723452327
1.957523723452327
1.9574944071588367
1.9574656623836952
1.9575775307197192
1.9576110706482155
1.957864357864358
1.9582499285101516
1.9583510412239693
1.9584503088152723
1.9585477813325916
1.9586435070306039
1.9584699453551913
1.9584699453551913
1.958299485513133
1.9586577181208054
1.9590098482832048
1.959356030614938
1.9596964145511646
1.9592683875989103
1.9594803190120915
1.9593402378212506
1.9596702599873177
1.959748427672956
1.9597087987950295
1.959679439018282
1.96
1.9603155040670446
1.9594280826102897
1.9596265761396703
1.9599374398460059
1.9598518341498388
1.9598518341498388
1.9598103141671606
1.96
1.96
1.9600700525394046
1.9594578941271863
1.9595309266498047
1.9596028757274906
1.9592298980747451
1.9595232741173825
1.9595232741173825
1.959267938846111
1.959556786703601
1.95953118089341
1.9594950603732162
1.9595008756567425
1.9597826086956522
1.9600604490500864
1.9603344768439108
1.9602048436999893
1.9600593283186778
1.9602272727272727
1.9600835945663533
1.9599874634350187
1.9601535747639307
1.9602143887858174
1.9601851851851853
1.9601471489883506
1.9601471489883506
1.9603085981118669
1.9604559669121355
1.960709632153954
1.9605695509309966
1.9606252473288484
1.960872984663783
1.9610237374230732
1.9610237374230732
1.9609822381830535
1.960941267238885
1.9607129168263702
1.9606741573033708
1.9608214251916343
1.960966892400301
1.960966892400301
1.9612004487658938
1.9610667162237503
1.9610667162237503
1.9612968778865694
1.961344229180057
1.9613910186199344
1.961437256147355
1.9615731553310483
total decoding steps: 21746 large model steps: 11086 avg decoding step: 1.9615731553310483
tensor([7.3246e-01, 8.5874e-02, 3.7976e-02, 2.1108e-02, 1.2809e-02, 1.0283e-02,
        8.8400e-03, 6.7653e-03, 4.1494e-03, 4.8710e-03, 3.9690e-03, 2.4355e-03,
        3.3375e-03, 2.9767e-03, 1.9845e-03, 2.7061e-03, 1.8943e-03, 9.9224e-04,
        1.7139e-03, 5.4122e-04, 2.3453e-03, 9.9224e-04, 1.2629e-03, 1.5335e-03,
        1.4433e-03, 1.1727e-03, 6.3143e-04, 1.0824e-03, 9.9224e-04, 9.0204e-04,
        3.6082e-04, 1.1727e-03, 3.8427e-02], device='cuda:0')
tensor([0.7325, 0.8183, 0.8563, 0.8774, 0.8902, 0.9005, 0.9093, 0.9161, 0.9203,
        0.9251, 0.9291, 0.9315, 0.9349, 0.9378, 0.9398, 0.9425, 0.9444, 0.9454,
        0.9471, 0.9477, 0.9500, 0.9510, 0.9523, 0.9538, 0.9553, 0.9564, 0.9571,
        0.9581, 0.9591, 0.9600, 0.9604, 0.9616, 1.0000], device='cuda:0')
